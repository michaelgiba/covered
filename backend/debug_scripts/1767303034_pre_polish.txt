Alright, let's check the inbox. We've got an email here from coveredappinbox@gmail.com. The subject line is: 'What is this' with a link to github.com/ASLP-lab/DiffRhythm. And the body of the email is just that same question: 'What is this' and the link. Let me pull this up and see what we're looking at.

Hey everyone. I've got a listener recommendation today for a project on GitHub called DiffRhythm. Let me read through the page for you. The title is GitHub - ASLP-lab/DiffRhythm: Diâ™ªâ™ªRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion. The authors are Ziqian Ning, Huakang Chen, Yuepeng Jiang, Chunbo Hao, Guobin Ma, Shuai Wang, Jixun Yao, and Lei Xie. Here is the full content: GitHub - ASLP-lab/DiffRhythm: Diâ™ªâ™ªRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion Skip to content Navigation Menu Toggle navigation Sign in Appearance settings Platform AI CODE CREATION GitHub Copilot Write better code with AI GitHub Spark Build and deploy intelligent apps GitHub Models Manage and compare prompts MCP Registry New Integrate external tools DEVELOPER WORKFLOWS Actions Automate any workflow Codespaces Instant dev environments Issues Plan and track work Code Review Manage code changes APPLICATION SECURITY GitHub Advanced Security Find and fix vulnerabilities Code security Secure your code as you build Secret protection Stop leaks before they start EXPLORE Why GitHub Documentation Blog Changelog Marketplace View all features Solutions BY COMPANY SIZE Enterprises Small and medium teams Startups Nonprofits BY USE CASE App Modernization DevSecOps DevOps CI/CD View all use cases BY INDUSTRY Healthcare Financial services Manufacturing Government View all industries View all solutions Resources EXPLORE BY TOPIC AI Software Development DevOps Security View all topics EXPLORE BY TYPE Customer stories Events & webinars Ebooks & reports Business insights GitHub Skills SUPPORT & SERVICES Documentation Customer support Community forum Trust center Partners Open Source COMMUNITY GitHub Sponsors Fund open source developers PROGRAMS Security Lab Maintainer Community Accelerator Archive Program REPOSITORIES Topics Trending Collections Enterprise ENTERPRISE SOLUTIONS Enterprise platform AI-powered developer platform AVAILABLE ADD-ONS GitHub Advanced Security Enterprise-grade security features Copilot for Business Enterprise-grade AI features Premium Support Enterprise-grade 24/7 support Pricing Search or jump to... Search code, repositories, users, issues, pull requests... Search Clear Search syntax tips Provide feedback We read every piece of feedback, and take your input very seriously. Include my email address so I can be contacted Cancel Submit feedback Saved searches Use saved searches to filter your results more quickly Name Query To see all available qualifiers, see our documentation . Cancel Create saved search Sign in Sign up Appearance settings Resetting focus You signed in with another tab or window. Reload to refresh your session. You signed out in another tab or window. Reload to refresh your session. You switched accounts on another tab or window. Reload to refresh your session. Dismiss alert ASLP-lab / DiffRhythm Public Notifications You must be signed in to change notification settings Fork 254 Star 2.2k Diâ™ªâ™ªRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion License Apache-2.0 license 2.2k stars 254 forks Branches Tags Activity Star Notifications You must be signed in to change notification settings Code Issues 45 Pull requests 7 Actions Projects 0 Security Uh oh! There was an error while loading. Please reload this page . Insights Additional navigation options Code Issues Pull requests Actions Projects Security Insights ASLP-lab/DiffRhythm main Branches Tags Go to file Code Open more actions menu Folders and files Name Name Last commit message Last commit date Latest commit History 62 Commits config config dataset dataset docker docker g2p g2p infer infer model model scripts scripts src src thirdparty/ LangSegment thirdparty/ LangSegment train train .gitignore .gitignore LICENSE.md LICENSE.md Readme.md Readme.md requirements.txt requirements.txt View all files Repository files navigation README Apache-2.0 license Diâ™ªâ™ªRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion Ziqian Ning, Huakang Chen, Yuepeng Jiang, Chunbo Hao, Guobin Ma, Shuai Wang, Jixun Yao, Lei Xieâ€  Huggingface Space Demo DiffRhythm 2 | ðŸ“‘ Paper | ðŸŽµ Demo DiffRhythm+ | ðŸ“‘ Paper | ðŸŽµ Demo DiffRhythm | ðŸ“‘ Paper | ðŸŽµ Demo | ðŸ’¬ WeChat (å¾®ä¿¡) DiffRhythm (Chinese: è°›éŸµ, DÃ¬ YÃ¹n) is the first open-sourced diffusion-based music generation model that is capable of creating full-length songs. The name combines "Diff" (referencing its diffusion architecture) with "Rhythm" (highlighting its focus on music and song creation). The Chinese name è°›éŸµ (DÃ¬ YÃ¹n) phonetically mirrors "DiffRhythm", where "è°›" (attentive listening) symbolizes auditory perception, and "éŸµ" (melodic charm) represents musicality. News and Updates ðŸ“Œ Join Us on Discord! 2025.5.9 ðŸ”¥ DiffRhythm-v1.2 Official Launch! Version 1.2 largely resolves repetition and omission issues, significantly improves audio quality and arrangement with richer instrumentation, and enables song editing and continuation with advanced understanding of music structure and style. 2025.3.15 ðŸ”¥ DiffRhythm-full Official Release: Complete Music Generation! The wait is over - 285s full-length music generation is now live! The symphony evolves. What impossible music will you compose next? 2025.3.11 ðŸ’» DiffRhythm can now run on MacOS! 2025.3.9 ðŸ”¥ DiffRhythm Update: Text-to-Music and Pure Music Generation! We're excited to announce two groundbreaking features now live in our open-source music model: ðŸŽ¯ Text-Based Style Prompts Describe styles/scenes in words (e.g., Jazzy Nightclub Vibe , Pop Emotional Piano or Indie folk ballad, coming-of-age themes, acoustic guitar picking with harmonica interludes ) â€” no audio reference needed! ðŸŽ§ Instrumental Mode Generate pure music with wild prompts like: " Arctic research station, theremin auroras dancing with geomagnetic storms " âœ¨ Special Thanks to community contributor @Jourdelune for implementing these features via #PR29! Full Release Notes : See src/update_alert.md for details, demos, and roadmap. Break the rules. Make music that shouldn't exist. 2025.3.7 ðŸ”¥ DiffRhythm is now officially licensed under the Apache 2.0 License ! ðŸŽ‰ As the first diffusion-based music generation model, DiffRhythm opens up exciting new possibilities for AI-driven creativity in music. Whether you're a researcher, developer, or music enthusiast, we invite you to explore, innovate, and build upon this foundation. 2025.3.6 ðŸ”¥ The local deployment guide is now available. 2025.3.4 ðŸ”¥ We released the DiffRhythm paper and Huggingface Space demo . TODOs Support Colab. Gradio support. Dynamic length control Vocals only Song extension Support Docker. Release DiffRhythm-full. Release training code. Support local deployment. Release paper to Arxiv. Online serving on Hugging Face Space. Model Versions Model HuggingFace DiffRhythm-v1.2-base (1m35s) https://huggingface.co/ASLP-lab/DiffRhythm-1_2 DiffRhythm-v1.2-full (4m45s) https://huggingface.co/ASLP-lab/DiffRhythm-1_2-full DiffRhythm-base (1m35s) https://huggingface.co/ASLP-lab/DiffRhythm-base DiffRhythm-full (4m45s) https://huggingface.co/ASLP-lab/DiffRhythm-full DiffRhythm-vae https://huggingface.co/ASLP-lab/DiffRhythm-vae Docker installation You just need the 3 files inside the folder docker. Do as it follows: Clone the project or copy the files cd into the folder Edit your docker compose biding folders docker compose up -d (or docker-compose up -d depending on your version) docker exec -it DiffRhythm bash You will be in the terminal ready for use. Just go to /home/app/scripts and run infer_prompt_ref.sh Inference Following the steps below to clone the repository and install the environment. # clone and enter the repositry git clone https://github.com/ASLP-lab/DiffRhythm.git cd DiffRhythm # install the environment # # espeak-ng # For Debian-like distribution (e.g. Ubuntu, Mint, etc.) sudo apt-get install espeak-ng # For RedHat-like distribution (e.g. CentOS, Fedora, etc.) sudo yum install espeak-ng # For MacOS brew install espeak-ng # For Windows # Please visit https://github.com/espeak-ng/espeak-ng/releases to download .msi installer # # create python environment conda create -n diffrhythm python=3.10 conda activate diffrhythm # # OR you can use classic Python virtual enviroment instead of conda python -m venv venv # activate venv on Linux source venv/bin/activate # activate venv on Windows venv \\Scripts\\activate # # install requirements pip install -r requirements.txt On Linux you can now simply use the inference script: # For inference using a reference WAV file bash scripts/infer_wav_ref.sh # For inference using a text prompt reference bash scripts/infer_prompt_ref.sh But before running the inference on Windows, make sure you set the user enviroment variables: PHONEMIZER_ESPEAK_LIBRARY -> C:\\Program Files\\eSpeak NG\\libespeak-ng.dll PHONEMIZER_ESPEAK_PATH -> C:\\Program Files\\eSpeak NG Change C:\\Program Files\\eSpeak NG to your eSpeak installation directory and reboot your PC to apply changes. Installing Japanese voices, mbrola binaries and unpacking an mbrola_ph folder (as described here and here ) are no longer required when running on Windows. See #17 (comment) , this and this commit . After this, you will also be able to run inference scripts on Windows (please note that English lyrics will be used here): rem : For inference using a reference WAV file call scripts\\infer_wav_ref.bat rem : For inference using a text prompt reference call scripts\\infer_prompt_ref.bat Example files of lrc and reference audio can be found in infer/example . You can use the tools we provide on huggingface to generate the lrc. Note that DiffRhythm-base requires a minimum of 8G of VRAM. To meet the 8G VRAM requirement, use the --chunked argument when running the inference. Higher VRAM may be required if chunked decoding is disabled. Training Coming soon... License & Disclaimer DiffRhythm (code and DiT weights) is released under the Apache License 2.0 . This open-source license allows you to freely use, modify, and distribute the model, as long as you include the appropriate copyright notice and disclaimer. We do not make any profit from this model. Our goal is to provide a high-quality base model for music generation, fostering innovation in AI music and contributing to the advancement of h. And that's it. Pretty deep dive into some cool audio tech. See you next time.